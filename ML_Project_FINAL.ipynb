{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm_KoHKwcPuj"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YU3Z9Oci0hGQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WedRwzF1zrB"
   },
   "source": [
    "Raw data retrieved from https://www.kaggle.com/datasets/pooriamst/occupancy-detection?resource=download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvI7XovAlSjr"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0qJhUyhTd-w",
    "outputId": "cfc69f78-4b62-4faa-81d7-4ec61ccb09f2"
   },
   "outputs": [],
   "source": [
    "# # Read the training and testing data\n",
    "# training = pd.read_csv(\"datatrain.csv\")\n",
    "# testing = pd.read_csv(\"datatest.csv\")\n",
    "\n",
    "# # Combine the training and testing data into one dataframe\n",
    "# combined_data = pd.concat([training, testing], ignore_index=True)\n",
    "\n",
    "# # Shuffle the dataset randomly \n",
    "# np.random.seed(24)\n",
    "# shuffled_data = combined_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# # Split by the 2:8 ratio (training is bigger)\n",
    "# train_ratio = 0.8\n",
    "# train_size = int(train_ratio * len(shuffled_data))\n",
    "\n",
    "# # split \n",
    "# new_train = shuffled_data[:train_size]\n",
    "# new_test = shuffled_data[train_size:]\n",
    "\n",
    "# # Write to their respective files\n",
    "# new_train.to_csv(\"new_train.csv\", index=False)\n",
    "# new_test.to_csv(\"new_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vflw54ap9oSr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/5gkyw8_j2h12l_25dp9m4k640000gn/T/ipykernel_2350/502833346.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n",
      "/var/folders/np/5gkyw8_j2h12l_25dp9m4k640000gn/T/ipykernel_2350/502833346.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n"
     ]
    }
   ],
   "source": [
    "def split_date_and_time(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day'] = df['date'].dt.strftime('%Y%m%d').astype(float)\n",
    "    df['time'] = df['date'].dt.hour + df['date'].dt.minute / 60 + df['date'].dt.second / 3600\n",
    "    return df\n",
    "\n",
    "# use manually split mixed data from across 2 weeks\n",
    "training_df = pd.read_csv(\"new_train.csv\")\n",
    "testing_df = pd.read_csv(\"new_test.csv\")\n",
    "\n",
    "train_features = split_date_and_time(training_df).drop(columns=[\"Occupancy\", \"id\", \"date\"])\n",
    "train_labels = training_df[\"Occupancy\"]\n",
    "\n",
    "testing_features = split_date_and_time(testing_df).drop(columns=[\"Occupancy\", \"id\", \"date\"])\n",
    "testing_labels = testing_df[\"Occupancy\"]\n",
    "\n",
    "X = train_features\n",
    "# print(X.head())\n",
    "Y = train_labels\n",
    "# print(Y.head())\n",
    "\n",
    "Z = testing_features\n",
    "# print(Z.head())\n",
    "Z_labels = testing_labels\n",
    "# print(Z_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT7zQa09cY-Q"
   },
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pZ2yyCeizPZQ"
   },
   "outputs": [],
   "source": [
    "model_accuracy = {}\n",
    "model_precision = {}\n",
    "model_recall = {}\n",
    "model_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics(labels, predictions, model_name):\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, zero_division=0)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "\n",
    "    model_accuracy[model_name] = accuracy\n",
    "    model_precision[model_name] = precision\n",
    "    model_recall[model_name] = recall\n",
    "    model_f1[model_name] = f1\n",
    "    print(f\"{model_name} accuracy: \", accuracy)\n",
    "    print(f\"{model_name} precision: \", precision)\n",
    "    print(f\"{model_name} recall: \", recall)\n",
    "    print(f\"{model_name} f1: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy:  0.9934338521400778\n",
      "Decision Tree precision:  0.987667009249743\n",
      "Decision Tree recall:  0.9846311475409836\n",
      "Decision Tree f1:  0.9861467419189328\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X, Y) # insert correct training data paths (X is training features, Y is training labels)\n",
    "predictions = dt.predict(Z) # insert correct testing data paths (Z is testing features)\n",
    "\n",
    "return_metrics(Z_labels, predictions, \"Decision Tree\") # compare performance against true testing labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge accuracy:  0.9890564202334631\n",
      "Ridge precision:  0.9586206896551724\n",
      "Ridge recall:  0.9969262295081968\n",
      "Ridge f1:  0.9773982923154194\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rc = linear_model.RidgeClassifier()\n",
    "rc.fit(X, Y)\n",
    "predictions = rc.predict(Z)\n",
    "\n",
    "return_metrics(Z_labels, predictions, \"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector accuracy:  0.7626459143968871\n",
      "Support Vector precision:  0.0\n",
      "Support Vector recall:  0.0\n",
      "Support Vector f1:  0.0\n",
      "\n",
      "Class Distribution in True Labels:\n",
      "Occupancy\n",
      "0    3136\n",
      "1     976\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution in Predictions:\n",
      "0    4112\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Decision Function Values:\n",
      "[-1.0000058  -1.00000441 -1.0000051  ... -1.00000572 -1.0000056\n",
      " -1.00000483]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC()\n",
    "svc.fit(X, Y)\n",
    "predictions = svc.predict(Z)\n",
    "\n",
    "return_metrics(Z_labels, predictions, \"Support Vector\")\n",
    "\n",
    "\n",
    "# view breakdowns to evaluate model performance\n",
    "print(\"\\nClass Distribution in True Labels:\")\n",
    "print(pd.Series(Z_labels).value_counts())  # count occurrences of each class in true labels\n",
    "\n",
    "print(\"\\nClass Distribution in Predictions:\")\n",
    "print(pd.Series(predictions).value_counts())  # count occurrences of each class in predictions\n",
    "\n",
    "decision_function = svc.decision_function(Z)  # get decision function values\n",
    "print(\"\\nDecision Function Values:\")\n",
    "print(decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  0.9929474708171206\n",
      "Random Forest precision:  0.984646878198567\n",
      "Random Forest recall:  0.985655737704918\n",
      "Random Forest f1:  0.9851510496671787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X, Y)\n",
    "predictions = clf.predict(Z)\n",
    "\n",
    "return_metrics(Z_labels, predictions, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy:  0.9922178988326849\n",
      "Gradient Boosting precision:  0.9777327935222672\n",
      "Gradient Boosting recall:  0.9897540983606558\n",
      "Gradient Boosting f1:  0.9837067209775967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "est = GradientBoostingClassifier()\n",
    "est = est.fit(X, Y) \n",
    "predictions = est.predict(Z)\n",
    "\n",
    "return_metrics(Z_labels, predictions, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Classifier Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBLrNWnIAK_V",
    "outputId": "2fe6d894-dbf8-4f27-cc2d-2fe28b5123f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Voting Ensemble accuracy:  0.9931906614785992\n",
      "Simple Voting Ensemble precision:  0.9866529774127311\n",
      "Simple Voting Ensemble recall:  0.9846311475409836\n",
      "Simple Voting Ensemble f1:  0.9856410256410256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create a voting classifier with our simple models\n",
    "simple_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', dt),\n",
    "        ('rc', rc),\n",
    "        ('svc', svc)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "simple_ensemble.fit(X, Y)\n",
    "ensemble_preds = simple_ensemble.predict(Z)\n",
    "return_metrics(Z_labels, ensemble_preds, \"Simple Voting Ensemble\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized return_metrics function for the parameter tuning\n",
    "def return_metrics(labels, predictions, model_name):\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, zero_division=0)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "\n",
    "    model_accuracy[model_name] = accuracy\n",
    "    model_precision[model_name] = precision\n",
    "    model_recall[model_name] = recall\n",
    "    model_f1[model_name] = f1\n",
    "\n",
    "    print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} precision: {precision:.4f}\")\n",
    "    print(f\"{model_name} recall: {recall:.4f}\")\n",
    "    print(f\"{model_name} f1: {f1:.4f}\")\n",
    "    \n",
    "    # return model_accuracy, model_precision, model_recall\n",
    "\n",
    "# function to help run everything\n",
    "def run(func, *args, **kwargs):\n",
    "    result = func(*args, **kwargs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Search:\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}\n",
      "Optimized Decision Tree accuracy: 0.9934\n",
      "Optimized Decision Tree precision: 0.9877\n",
      "Optimized Decision Tree recall: 0.9846\n",
      "Optimized Decision Tree f1: 0.9861\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Decision Tree\n",
    "dt_param_dist = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_random = run(\n",
    "    RandomizedSearchCV,\n",
    "    tree.DecisionTreeClassifier(random_state=42),\n",
    "    param_distributions=dt_param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_random = run(dt_random.fit, X, Y)\n",
    "print(\"Best parameters found by Random Search:\")\n",
    "print(dt_random.best_params_)\n",
    "\n",
    "best_dt = dt_random.best_estimator_\n",
    "dt_predictions = best_dt.predict(Z)\n",
    "return_metrics(Z_labels, dt_predictions, \"Optimized Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Search:\n",
      "{'solver': 'cholesky', 'class_weight': None, 'alpha': 0.1}\n",
      "Optimized Ridge accuracy: 0.9891\n",
      "Optimized Ridge precision: 0.9586\n",
      "Optimized Ridge recall: 0.9969\n",
      "Optimized Ridge f1: 0.9774\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Ridge Classifier\n",
    "ridge_param_dist = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "ridge_random = run(\n",
    "    RandomizedSearchCV,\n",
    "    linear_model.RidgeClassifier(random_state=42),\n",
    "    param_distributions=ridge_param_dist,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ridge_random = run(ridge_random.fit, X, Y)\n",
    "print(\"Best parameters found by Random Search:\")\n",
    "print(ridge_random.best_params_)\n",
    "\n",
    "best_ridge = ridge_random.best_estimator_\n",
    "ridge_predictions = best_ridge.predict(Z)\n",
    "return_metrics(Z_labels, ridge_predictions, \"Optimized Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Search (on sample):\n",
      "{'kernel': 'linear', 'gamma': 'auto', 'C': 5.0}\n",
      "Sample-trained SVM accuracy: 0.7626\n",
      "Sample-trained SVM precision: 0.0000\n",
      "Sample-trained SVM recall: 0.0000\n",
      "Sample-trained SVM f1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sample_size = min(100, X.shape[0]) # 100 samples\n",
    "indices = np.random.choice(X.shape[0], size=sample_size, replace=False)\n",
    "X_sample = X.iloc[indices]\n",
    "Y_sample = Y.iloc[indices]\n",
    "\n",
    "svm_param_dist = {\n",
    "    'C': [0.1, 1.0,5.0],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_random = run(\n",
    "    RandomizedSearchCV,\n",
    "    svm.SVC(probability=True, random_state=42),\n",
    "    param_distributions=svm_param_dist,\n",
    "    n_iter=5,\n",
    "    cv=2,\n",
    "    scoring='precision',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_random = run(svm_random.fit, X_sample, Y_sample)\n",
    "print(\"Best parameters found by Random Search (on sample):\")\n",
    "print(svm_random.best_params_)\n",
    "\n",
    "best_svm = svm_random.best_estimator_\n",
    "svm_predictions = best_svm.predict(Z)\n",
    "return_metrics(Z_labels, svm_predictions, \"Sample-trained SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Search:\n",
      "{'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20, 'bootstrap': False}\n",
      "Optimized Random Forest accuracy: 0.9934\n",
      "Optimized Random Forest precision: 0.9867\n",
      "Optimized Random Forest recall: 0.9857\n",
      "Optimized Random Forest f1: 0.9862\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Random Forest\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random = run(\n",
    "    RandomizedSearchCV,\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_random = run(rf_random.fit, X, Y)\n",
    "print(\"Best parameters found by Random Search:\")\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "best_rf = rf_random.best_estimator_\n",
    "rf_predictions = best_rf.predict(Z)\n",
    "return_metrics(Z_labels, rf_predictions, \"Optimized Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by Random Search:\n",
      "{'subsample': 1.0, 'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "Optimized Gradient Boosting accuracy: 0.9939\n",
      "Optimized Gradient Boosting precision: 0.9837\n",
      "Optimized Gradient Boosting recall: 0.9908\n",
      "Optimized Gradient Boosting f1: 0.9872\n"
     ]
    }
   ],
   "source": [
    "# Random Search for Gradient Boosting\n",
    "gb_param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb_random = run(\n",
    "    RandomizedSearchCV,\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions=gb_param_dist,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_random = run(gb_random.fit, X, Y)\n",
    "print(\"Best parameters found by Random Search:\")\n",
    "print(gb_random.best_params_)\n",
    "\n",
    "best_gb = gb_random.best_estimator_\n",
    "gb_predictions = best_gb.predict(Z)\n",
    "return_metrics(Z_labels, gb_predictions, \"Optimized Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Simple Voting Ensemble accuracy: 0.9932\n",
      "Optimized Simple Voting Ensemble precision: 0.9877\n",
      "Optimized Simple Voting Ensemble recall: 0.9836\n",
      "Optimized Simple Voting Ensemble f1: 0.9856\n"
     ]
    }
   ],
   "source": [
    "# Create a simple voting classifier with our tuned simple models\n",
    "simple_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', best_dt),\n",
    "        ('ridge', best_ridge),\n",
    "        ('svm', best_svm)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "simple_ensemble = run(simple_ensemble.fit, X, Y)\n",
    "ensemble_preds = simple_ensemble.predict(Z)\n",
    "return_metrics(Z_labels, ensemble_preds, \"Optimized Simple Voting Ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RZhSlWApilij",
    "outputId": "0721287f-a473-4199-aa53-5de6dfc60cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ACCURACY for binary occupancy detection model is Optimized Gradient Boosting with an accuracy of 0.993920233463035\n",
      "\t('Support Vector', 0.7626459143968871)\n",
      "\t('Sample-trained SVM', 0.7626459143968871)\n",
      "\t('Ridge', 0.9890564202334631)\n",
      "\t('Optimized Ridge', 0.9890564202334631)\n",
      "\t('Gradient Boosting', 0.9922178988326849)\n",
      "\t('Random Forest', 0.9929474708171206)\n",
      "\t('Simple Voting Ensemble', 0.9931906614785992)\n",
      "\t('Optimized Simple Voting Ensemble', 0.9931906614785992)\n",
      "\t('Decision Tree', 0.9934338521400778)\n",
      "\t('Optimized Decision Tree', 0.9934338521400778)\n",
      "\t('Optimized Random Forest', 0.9934338521400778)\n",
      "\t('Optimized Gradient Boosting', 0.993920233463035)\n",
      "Best PRECISION for binary occupancy detection model is Decision Tree with a precision of 0.987667009249743\n",
      "\t('Support Vector', 0.0)\n",
      "\t('Sample-trained SVM', 0.0)\n",
      "\t('Ridge', 0.9586206896551724)\n",
      "\t('Optimized Ridge', 0.9586206896551724)\n",
      "\t('Gradient Boosting', 0.9777327935222672)\n",
      "\t('Optimized Gradient Boosting', 0.9837232960325534)\n",
      "\t('Random Forest', 0.984646878198567)\n",
      "\t('Simple Voting Ensemble', 0.9866529774127311)\n",
      "\t('Optimized Random Forest', 0.9866666666666667)\n",
      "\t('Optimized Simple Voting Ensemble', 0.9876543209876543)\n",
      "\t('Decision Tree', 0.987667009249743)\n",
      "\t('Optimized Decision Tree', 0.987667009249743)\n",
      "Best RECALL for binary occupancy detection model is Ridge with a recall of 0.9586206896551724\n",
      "\t('Support Vector', 0.0)\n",
      "\t('Sample-trained SVM', 0.0)\n",
      "\t('Optimized Simple Voting Ensemble', 0.9836065573770492)\n",
      "\t('Decision Tree', 0.9846311475409836)\n",
      "\t('Simple Voting Ensemble', 0.9846311475409836)\n",
      "\t('Optimized Decision Tree', 0.9846311475409836)\n",
      "\t('Random Forest', 0.985655737704918)\n",
      "\t('Optimized Random Forest', 0.985655737704918)\n",
      "\t('Gradient Boosting', 0.9897540983606558)\n",
      "\t('Optimized Gradient Boosting', 0.9907786885245902)\n",
      "\t('Ridge', 0.9969262295081968)\n",
      "\t('Optimized Ridge', 0.9969262295081968)\n",
      "Best F1 for binary occupancy detection model is Optimized Gradient Boosting with an f1 of 0.9872383869321082\n",
      "\t('Support Vector', 0.0)\n",
      "\t('Sample-trained SVM', 0.0)\n",
      "\t('Ridge', 0.9773982923154194)\n",
      "\t('Optimized Ridge', 0.9773982923154194)\n",
      "\t('Gradient Boosting', 0.9837067209775967)\n",
      "\t('Random Forest', 0.9851510496671787)\n",
      "\t('Optimized Simple Voting Ensemble', 0.9856262833675564)\n",
      "\t('Simple Voting Ensemble', 0.9856410256410256)\n",
      "\t('Decision Tree', 0.9861467419189328)\n",
      "\t('Optimized Decision Tree', 0.9861467419189328)\n",
      "\t('Optimized Random Forest', 0.9861609431060995)\n",
      "\t('Optimized Gradient Boosting', 0.9872383869321082)\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_model = max(model_accuracy, key = model_accuracy.get)\n",
    "best_precision_model = max(model_precision, key = model_precision.get)\n",
    "best_recall_model = max(model_recall, key = model_recall.get)\n",
    "best_f1_model = max(model_f1, key = model_f1.get)\n",
    "\n",
    "print(f\"Best ACCURACY for binary occupancy detection model is {best_accuracy_model} with an accuracy of {model_accuracy[best_accuracy_model]}\")\n",
    "for model in sorted(model_accuracy.items(), key=lambda item: item[1]):\n",
    "    print(f\"\\t{model}\")\n",
    "print(f\"Best PRECISION for binary occupancy detection model is {best_precision_model} with a precision of {model_precision[best_precision_model]}\")\n",
    "for model in sorted(model_precision.items(), key=lambda item: item[1]):\n",
    "    print(f\"\\t{model}\")\n",
    "print(f\"Best RECALL for binary occupancy detection model is {best_recall_model} with a recall of {model_precision[best_recall_model]}\")\n",
    "for model in sorted(model_recall.items(), key=lambda item: item[1]):\n",
    "    print(f\"\\t{model}\")\n",
    "print(f\"Best F1 for binary occupancy detection model is {best_f1_model} with an f1 of {model_f1[best_f1_model]}\")\n",
    "for model in sorted(model_f1.items(), key=lambda item: item[1]):\n",
    "    print(f\"\\t{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Dataset (50/50 Split Occupied/Unoccupied)\n",
    "\n",
    "To fix the issue with the SVM evaluation results, we decided to modify the dataset by balancing the number of data points labeled Occupied vs Unoccupied and retrained all the models based off the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Occupancy\n",
      "0    12674\n",
      "1     3774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced class distribution:\n",
      "Occupancy\n",
      "0    3774\n",
      "1    3774\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine features and labels into one DataFrame\n",
    "df_full = pd.concat([X, Y], axis=1)\n",
    "df_full.columns = list(X.columns) + ['Occupancy']\n",
    "\n",
    "# Separate the classes\n",
    "occupied = df_full[df_full['Occupancy'] == 1]\n",
    "unoccupied = df_full[df_full['Occupancy'] == 0]\n",
    "\n",
    "# Undersample the majority class to match the minority\n",
    "unoccupied_downsampled = resample(unoccupied,\n",
    "                                  replace=False,\n",
    "                                  n_samples=len(occupied),\n",
    "                                  random_state=42)\n",
    "\n",
    "# Combine to get balanced dataset\n",
    "balanced_df = pd.concat([occupied, unoccupied_downsampled])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split features and labels again\n",
    "X_balanced = balanced_df.drop(columns=['Occupancy'])\n",
    "Y_balanced = balanced_df['Occupancy']\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(Y.value_counts())\n",
    "\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(Y_balanced.value_counts())\n",
    "\n",
    "# Split balanced data into training and testing sets\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(\n",
    "    X_balanced, Y_balanced,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y_balanced  # preserve class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM on Balanced + Scaled Data accuracy: 0.9881\n",
      "Tuned SVM on Balanced + Scaled Data precision: 0.9804\n",
      "Tuned SVM on Balanced + Scaled Data recall: 0.9960\n",
      "Tuned SVM on Balanced + Scaled Data f1: 0.9882\n",
      "\n",
      "Class Distribution in Predictions:\n",
      "1    767\n",
      "0    743\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the balanced data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
    "X_test_scaled = scaler.transform(X_test_bal)\n",
    "\n",
    "# Using best parameters found from tuning\n",
    "best_svm = SVC(C=5.0, kernel='linear', gamma='auto', probability=True) \n",
    "best_svm.fit(X_train_scaled, y_train_bal)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bal_scaled = best_svm.predict(X_test_scaled)\n",
    "return_metrics(y_test_bal, y_pred_bal_scaled, \"Tuned SVM on Balanced + Scaled Data\")\n",
    "\n",
    "# Checking predictions\n",
    "import pandas as pd\n",
    "print(\"\\nClass Distribution in Predictions:\")\n",
    "print(pd.Series(y_pred_bal_scaled).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Decision Tree accuracy: 0.9894\n",
      "Balanced Decision Tree precision: 0.9855\n",
      "Balanced Decision Tree recall: 0.9934\n",
      "Balanced Decision Tree f1: 0.9894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_bal = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "dt_bal.fit(X_train_bal, y_train_bal)\n",
    "y_pred_dt = dt_bal.predict(X_test_bal)\n",
    "return_metrics(y_test_bal, y_pred_dt, \"Balanced Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Ridge Classifier accuracy: 0.9841\n",
      "Balanced Ridge Classifier precision: 0.9716\n",
      "Balanced Ridge Classifier recall: 0.9974\n",
      "Balanced Ridge Classifier f1: 0.9843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_bal = RidgeClassifier(\n",
    "    alpha=0.1,\n",
    "    solver='cholesky',\n",
    "    class_weight=None\n",
    ")\n",
    "ridge_bal.fit(X_train_scaled, y_train_bal)\n",
    "y_pred_ridge = ridge_bal.predict(X_test_scaled)\n",
    "return_metrics(y_test_bal, y_pred_ridge, \"Balanced Ridge Classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest accuracy: 0.9901\n",
      "Balanced Random Forest precision: 0.9868\n",
      "Balanced Random Forest recall: 0.9934\n",
      "Balanced Random Forest f1: 0.9901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_bal = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "rf_bal.fit(X_train_bal, y_train_bal)\n",
    "y_pred_rf = rf_bal.predict(X_test_bal)\n",
    "return_metrics(y_test_bal, y_pred_rf, \"Balanced Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Gradient Boosting accuracy: 0.9894\n",
      "Balanced Gradient Boosting precision: 0.9830\n",
      "Balanced Gradient Boosting recall: 0.9960\n",
      "Balanced Gradient Boosting f1: 0.9895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_bal = GradientBoostingClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    min_samples_split=5,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "gb_bal.fit(X_train_scaled, y_train_bal)\n",
    "y_pred_gb = gb_bal.predict(X_test_scaled)\n",
    "return_metrics(y_test_bal, y_pred_gb, \"Balanced Gradient Boosting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Simple Ensemble accuracy: 0.9894\n",
      "Balanced Simple Ensemble precision: 0.9855\n",
      "Balanced Simple Ensemble recall: 0.9934\n",
      "Balanced Simple Ensemble f1: 0.9894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_bal = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', dt_bal),\n",
    "        ('ridge', ridge_bal),\n",
    "        ('svm', best_svm)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "ensemble_bal.fit(X_train_bal, y_train_bal)\n",
    "y_pred_ensemble = ensemble_bal.predict(X_test_bal)\n",
    "return_metrics(y_test_bal, y_pred_ensemble, \"Balanced Simple Ensemble\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bm_KoHKwcPuj",
    "tvI7XovAlSjr",
    "Khu0NaNqzJEK"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
